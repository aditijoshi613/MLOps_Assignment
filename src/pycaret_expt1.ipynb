{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pycaret_expt1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiiyNQiQpnIb",
        "outputId": "a6269143-ae48-4e28-c819-3dcf24b16114"
      },
      "source": [
        "!pip install pycaret"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycaret\n",
            "  Downloading pycaret-2.3.2-py3-none-any.whl (263 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▎                              | 10 kB 26.5 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 20 kB 29.3 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 30 kB 20.2 MB/s eta 0:00:01\r\u001b[K     |█████                           | 40 kB 16.8 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 51 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 61 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 71 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 81 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 92 kB 9.7 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 102 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 112 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 122 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 133 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 143 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 153 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 163 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 174 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 184 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 194 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 204 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 215 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 225 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 235 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 245 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 256 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 263 kB 7.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cufflinks>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.17.3)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.15.3)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.5.0)\n",
            "Collecting pyLDAvis\n",
            "  Downloading pyLDAvis-3.3.1.tar.gz (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 14.3 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting kmodes>=0.10.1\n",
            "  Downloading kmodes-0.11.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting mlxtend>=0.17.0\n",
            "  Downloading mlxtend-0.18.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 44.7 MB/s \n",
            "\u001b[?25hCollecting pandas-profiling>=2.8.0\n",
            "  Downloading pandas_profiling-3.0.0-py2.py3-none-any.whl (248 kB)\n",
            "\u001b[K     |████████████████████████████████| 248 kB 50.4 MB/s \n",
            "\u001b[?25hCollecting umap-learn\n",
            "  Downloading umap-learn-0.5.1.tar.gz (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 10.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from pycaret) (7.6.3)\n",
            "Requirement already satisfied: spacy<2.4.0 in /usr/local/lib/python3.7/dist-packages (from pycaret) (2.2.4)\n",
            "Requirement already satisfied: gensim<4.0.0 in /usr/local/lib/python3.7/dist-packages (from pycaret) (3.6.0)\n",
            "Collecting lightgbm>=2.3.1\n",
            "  Downloading lightgbm-3.2.1-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 47.8 MB/s \n",
            "\u001b[?25hCollecting scikit-plot\n",
            "  Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.19.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.0.1)\n",
            "Collecting scikit-learn==0.23.2\n",
            "  Downloading scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 49.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.11.1)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (from pycaret) (5.5.0)\n",
            "Requirement already satisfied: scipy<=1.5.4 in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.4.1)\n",
            "Collecting pyod\n",
            "  Downloading pyod-0.9.0.tar.gz (105 kB)\n",
            "\u001b[K     |████████████████████████████████| 105 kB 59.7 MB/s \n",
            "\u001b[?25hCollecting imbalanced-learn==0.7.0\n",
            "  Downloading imbalanced_learn-0.7.0-py3-none-any.whl (167 kB)\n",
            "\u001b[K     |████████████████████████████████| 167 kB 47.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: plotly>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from pycaret) (4.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from pycaret) (3.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.1.5)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from pycaret) (3.2.5)\n",
            "Collecting yellowbrick>=1.0.1\n",
            "  Downloading yellowbrick-1.3.post1-py3-none-any.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 61.8 MB/s \n",
            "\u001b[?25hCollecting Boruta\n",
            "  Downloading Boruta-0.3-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 5.7 MB/s \n",
            "\u001b[?25hCollecting mlflow\n",
            "  Downloading mlflow-1.19.0-py3-none-any.whl (14.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.4 MB 60 kB/s \n",
            "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-2.2.0-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: setuptools>=34.4.1 in /usr/local/lib/python3.7/dist-packages (from cufflinks>=0.17.0->pycaret) (57.2.0)\n",
            "Requirement already satisfied: colorlover>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from cufflinks>=0.17.0->pycaret) (0.3.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from cufflinks>=0.17.0->pycaret) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim<4.0.0->pycaret) (5.1.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (4.4.2)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (0.8.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (5.0.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (4.8.0)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret) (5.1.3)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret) (1.0.0)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret) (3.5.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret) (4.10.1)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (5.1.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (5.3.5)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm>=2.3.1->pycaret) (0.36.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pycaret) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pycaret) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pycaret) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pycaret) (2.4.7)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (4.7.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (2.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (0.2.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->pycaret) (2018.9)\n",
            "Collecting requests>=2.24.0\n",
            "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.0 MB/s \n",
            "\u001b[?25hCollecting phik>=0.11.1\n",
            "  Downloading phik-0.11.2.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 17.0 MB/s \n",
            "\u001b[?25hCollecting tangled-up-in-unicode==0.1.0\n",
            "  Downloading tangled_up_in_unicode-0.1.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 42.2 MB/s \n",
            "\u001b[?25hCollecting visions[type_image_path]==0.7.1\n",
            "  Downloading visions-0.7.1-py3-none-any.whl (102 kB)\n",
            "\u001b[K     |████████████████████████████████| 102 kB 76.8 MB/s \n",
            "\u001b[?25hCollecting pydantic>=1.8.1\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 41.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (2.11.3)\n",
            "Collecting htmlmin>=0.1.12\n",
            "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n",
            "Collecting tqdm>=4.48.2\n",
            "  Downloading tqdm-4.61.2-py2.py3-none-any.whl (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 5.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: missingno>=0.4.2 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (0.5.0)\n",
            "Collecting PyYAML>=5.0.0\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 52.2 MB/s \n",
            "\u001b[?25hCollecting multimethod==1.4\n",
            "  Downloading multimethod-1.4-py2.py3-none-any.whl (7.3 kB)\n",
            "Requirement already satisfied: attrs>=19.3.0 in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.1->pandas-profiling>=2.8.0->pycaret) (21.2.0)\n",
            "Requirement already satisfied: bottleneck in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.1->pandas-profiling>=2.8.0->pycaret) (1.3.2)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.1->pandas-profiling>=2.8.0->pycaret) (2.5.1)\n",
            "Collecting imagehash\n",
            "  Downloading ImageHash-4.2.1.tar.gz (812 kB)\n",
            "\u001b[K     |████████████████████████████████| 812 kB 39.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.1->pandas-profiling>=2.8.0->pycaret) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.11.1->pandas-profiling>=2.8.0->pycaret) (2.0.1)\n",
            "Collecting scipy<=1.5.4\n",
            "  Downloading scipy-1.5.4-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9 MB 967 bytes/s \n",
            "\u001b[?25hRequirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly>=4.4.1->pycaret) (1.3.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->pycaret) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pydantic>=1.8.1->pandas-profiling>=2.8.0->pycaret) (3.7.4.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret) (1.24.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret) (2.0.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret) (2021.5.30)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (3.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (1.0.5)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (0.8.2)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (1.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (0.4.1)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (1.1.3)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (7.4.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (2.0.5)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0->pycaret) (4.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0->pycaret) (3.5.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets->pycaret) (5.3.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.7.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (5.6.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.10.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets->pycaret) (22.1.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.7.0)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.7/dist-packages (from imagehash->visions[type_image_path]==0.7.1->pandas-profiling>=2.8.0->pycaret) (1.1.1)\n",
            "Collecting alembic<=1.4.1\n",
            "  Downloading alembic-1.4.1.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 29.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (3.17.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (0.3)\n",
            "Collecting gunicorn\n",
            "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 9.2 MB/s \n",
            "\u001b[?25hCollecting prometheus-flask-exporter\n",
            "  Downloading prometheus_flask_exporter-0.18.2.tar.gz (22 kB)\n",
            "Collecting querystring-parser\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (1.1.4)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (1.4.20)\n",
            "Collecting databricks-cli>=0.8.7\n",
            "  Downloading databricks-cli-0.14.3.tar.gz (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (1.3.0)\n",
            "Collecting docker>=4.0.0\n",
            "  Downloading docker-5.0.0-py2.py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 55.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (0.4.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (7.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (21.0)\n",
            "Collecting gitpython>=2.1.0\n",
            "  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\n",
            "\u001b[K     |████████████████████████████████| 170 kB 59.2 MB/s \n",
            "\u001b[?25hCollecting Mako\n",
            "  Downloading Mako-1.1.4-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 4.7 MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow->pycaret) (0.8.9)\n",
            "Collecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-1.1.0-py2.py3-none-any.whl (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 7.6 MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.9 MB/s \n",
            "\u001b[?25hCollecting smmap<5,>=3.0.1\n",
            "  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->mlflow->pycaret) (1.1.0)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow->pycaret) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow->pycaret) (1.0.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.4.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (3.3.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.7.1)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.5.1)\n",
            "Requirement already satisfied: prometheus_client in /usr/local/lib/python3.7/dist-packages (from prometheus-flask-exporter->mlflow->pycaret) (0.11.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis->pycaret) (2.7.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis->pycaret) (0.16.0)\n",
            "Collecting pyLDAvis\n",
            "  Downloading pyLDAvis-3.3.0.tar.gz (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 29.8 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading pyLDAvis-3.2.2.tar.gz (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 32.2 MB/s \n",
            "\u001b[?25hCollecting funcy\n",
            "  Downloading funcy-1.16-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: numba>=0.35 in /usr/local/lib/python3.7/dist-packages (from pyod->pycaret) (0.51.2)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from pyod->pycaret) (0.10.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.35->pyod->pycaret) (0.34.0)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels->pyod->pycaret) (0.5.1)\n",
            "Collecting pynndescent>=0.5\n",
            "  Downloading pynndescent-0.5.4.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 33.9 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: htmlmin, phik, imagehash, alembic, databricks-cli, prometheus-flask-exporter, pyLDAvis, pyod, umap-learn, pynndescent\n",
            "  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27098 sha256=7fae08f00dae951c0d26435eee4c512e7fc328ad77366dd4e2bd2f068d970637\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/e1/52/5b14d250ba868768823940c3229e9950d201a26d0bd3ee8655\n",
            "  Building wheel for phik (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for phik: filename=phik-0.11.2-py3-none-any.whl size=1107437 sha256=e747726a31d19b5aacf30618160dac0308733c965006056fa08bdc1af3961e1f\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/98/a3/b654f24edcdcdb87d1f70d65a506fcfdf15289db129c594bcd\n",
            "  Building wheel for imagehash (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imagehash: filename=ImageHash-4.2.1-py2.py3-none-any.whl size=295206 sha256=d568f54ea85cb1a5250fc60a3f82987e807948670ba6683482d32389b1cae0aa\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/d5/59/5e3e297533ddb09407769762985d134135064c6831e29a914e\n",
            "  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158170 sha256=0551111db4d10f6725d2ec7f06f1c4699a89ab09b669690ae5ea6ed7b5dcf2a7\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/5d/0a/9e13f53f4f5dfb67cd8d245bb7cdffe12f135846f491a283e3\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.14.3-py3-none-any.whl size=100557 sha256=f95b5fc2d1df4123674a47dad4ce20d105646ced6a8e9792c16584b9d5a5a33b\n",
            "  Stored in directory: /root/.cache/pip/wheels/3b/60/14/6930445b08959fbdf4e3029bac7e1f2cccb2e94df8afa00b29\n",
            "  Building wheel for prometheus-flask-exporter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for prometheus-flask-exporter: filename=prometheus_flask_exporter-0.18.2-py3-none-any.whl size=17416 sha256=1b30fa7e55d303fe6bd0722049aa688505a400029aab8bcbebe903755b0a3651\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/1e/1c/c765920cb92b2f0343d2dd8b481a407cee2823f9b4bbd2e52a\n",
            "  Building wheel for pyLDAvis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyLDAvis: filename=pyLDAvis-3.2.2-py2.py3-none-any.whl size=135618 sha256=0702a24ddaec1a17c598621cea4fd3f7193b69b1488730ef9a146b6072b6a1e8\n",
            "  Stored in directory: /root/.cache/pip/wheels/f8/b1/9b/560ac1931796b7303f7b517b949d2d31a4fbc512aad3b9f284\n",
            "  Building wheel for pyod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyod: filename=pyod-0.9.0-py3-none-any.whl size=122560 sha256=22fff10ed4040efd1a1266fff4fe010f85e3de37906af863cbb3031f69c35b94\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/5f/59/5984a6116a4d19aee28d8ebeffd431364ce1cf21eb73a6ad34\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.1-py3-none-any.whl size=76566 sha256=7c2c46c0ce7e82cc96dbdd222fb91e05952be32ed91d2f6a0044f1a7c2fca163\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/e7/bb/347dc0e510803d7116a13d592b10cc68262da56a8eec4dd72f\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.4-py3-none-any.whl size=52372 sha256=883c2b24ad01ed990875032fe5420aec74b84eb5b04609d4c5095a580ccd0cf0\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/5b/62/3401692ddad12324249c774c4b15ccb046946021e2b581c043\n",
            "Successfully built htmlmin phik imagehash alembic databricks-cli prometheus-flask-exporter pyLDAvis pyod umap-learn pynndescent\n",
            "Installing collected packages: threadpoolctl, tangled-up-in-unicode, smmap, scipy, multimethod, websocket-client, visions, tqdm, scikit-learn, requests, python-editor, Mako, imagehash, gitdb, querystring-parser, PyYAML, pynndescent, pydantic, prometheus-flask-exporter, phik, htmlmin, gunicorn, gitpython, funcy, docker, databricks-cli, alembic, yellowbrick, umap-learn, scikit-plot, pyod, pyLDAvis, pandas-profiling, mlxtend, mlflow, lightgbm, kmodes, imbalanced-learn, Boruta, pycaret\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: yellowbrick\n",
            "    Found existing installation: yellowbrick 0.9.1\n",
            "    Uninstalling yellowbrick-0.9.1:\n",
            "      Successfully uninstalled yellowbrick-0.9.1\n",
            "  Attempting uninstall: pandas-profiling\n",
            "    Found existing installation: pandas-profiling 1.4.1\n",
            "    Uninstalling pandas-profiling-1.4.1:\n",
            "      Successfully uninstalled pandas-profiling-1.4.1\n",
            "  Attempting uninstall: mlxtend\n",
            "    Found existing installation: mlxtend 0.14.0\n",
            "    Uninstalling mlxtend-0.14.0:\n",
            "      Successfully uninstalled mlxtend-0.14.0\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "  Attempting uninstall: imbalanced-learn\n",
            "    Found existing installation: imbalanced-learn 0.4.3\n",
            "    Uninstalling imbalanced-learn-0.4.3:\n",
            "      Successfully uninstalled imbalanced-learn-0.4.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Boruta-0.3 Mako-1.1.4 PyYAML-5.4.1 alembic-1.4.1 databricks-cli-0.14.3 docker-5.0.0 funcy-1.16 gitdb-4.0.7 gitpython-3.1.18 gunicorn-20.1.0 htmlmin-0.1.12 imagehash-4.2.1 imbalanced-learn-0.7.0 kmodes-0.11.0 lightgbm-3.2.1 mlflow-1.19.0 mlxtend-0.18.0 multimethod-1.4 pandas-profiling-3.0.0 phik-0.11.2 prometheus-flask-exporter-0.18.2 pyLDAvis-3.2.2 pycaret-2.3.2 pydantic-1.8.2 pynndescent-0.5.4 pyod-0.9.0 python-editor-1.0.4 querystring-parser-1.2.4 requests-2.26.0 scikit-learn-0.23.2 scikit-plot-0.3.7 scipy-1.5.4 smmap-4.0.0 tangled-up-in-unicode-0.1.0 threadpoolctl-2.2.0 tqdm-4.61.2 umap-learn-0.5.1 visions-0.7.1 websocket-client-1.1.0 yellowbrick-1.3.post1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zKOetNFVpDax"
      },
      "source": [
        "import pandas as pd \n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oUsfnRtm8Ek",
        "outputId": "ba54396e-577e-469f-8e78-2b1e0a295c47"
      },
      "source": [
        "from google.colab import drive   #wget! is also an option to directly access from github\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "om34u2tPovrI",
        "outputId": "931d528c-f429-4672-aede-2271cf9ebf2e"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "r_IvfGepoxip",
        "outputId": "5d39ae8b-56c4-413d-a013-aa050a8601ff"
      },
      "source": [
        "df = pd.read_csv('drive/My Drive/creditcard.csv')\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>-0.551600</td>\n",
              "      <td>-0.617801</td>\n",
              "      <td>-0.991390</td>\n",
              "      <td>-0.311169</td>\n",
              "      <td>1.468177</td>\n",
              "      <td>-0.470401</td>\n",
              "      <td>0.207971</td>\n",
              "      <td>0.025791</td>\n",
              "      <td>0.403993</td>\n",
              "      <td>0.251412</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>1.612727</td>\n",
              "      <td>1.065235</td>\n",
              "      <td>0.489095</td>\n",
              "      <td>-0.143772</td>\n",
              "      <td>0.635558</td>\n",
              "      <td>0.463917</td>\n",
              "      <td>-0.114805</td>\n",
              "      <td>-0.183361</td>\n",
              "      <td>-0.145783</td>\n",
              "      <td>-0.069083</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>0.624501</td>\n",
              "      <td>0.066084</td>\n",
              "      <td>0.717293</td>\n",
              "      <td>-0.165946</td>\n",
              "      <td>2.345865</td>\n",
              "      <td>-2.890083</td>\n",
              "      <td>1.109969</td>\n",
              "      <td>-0.121359</td>\n",
              "      <td>-2.261857</td>\n",
              "      <td>0.524980</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>-0.226487</td>\n",
              "      <td>0.178228</td>\n",
              "      <td>0.507757</td>\n",
              "      <td>-0.287924</td>\n",
              "      <td>-0.631418</td>\n",
              "      <td>-1.059647</td>\n",
              "      <td>-0.684093</td>\n",
              "      <td>1.965775</td>\n",
              "      <td>-1.232622</td>\n",
              "      <td>-0.208038</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>-0.822843</td>\n",
              "      <td>0.538196</td>\n",
              "      <td>1.345852</td>\n",
              "      <td>-1.119670</td>\n",
              "      <td>0.175121</td>\n",
              "      <td>-0.451449</td>\n",
              "      <td>-0.237033</td>\n",
              "      <td>-0.038195</td>\n",
              "      <td>0.803487</td>\n",
              "      <td>0.408542</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-0.425966</td>\n",
              "      <td>0.960523</td>\n",
              "      <td>1.141109</td>\n",
              "      <td>-0.168252</td>\n",
              "      <td>0.420987</td>\n",
              "      <td>-0.029728</td>\n",
              "      <td>0.476201</td>\n",
              "      <td>0.260314</td>\n",
              "      <td>-0.568671</td>\n",
              "      <td>-0.371407</td>\n",
              "      <td>1.341262</td>\n",
              "      <td>0.359894</td>\n",
              "      <td>-0.358091</td>\n",
              "      <td>-0.137134</td>\n",
              "      <td>0.517617</td>\n",
              "      <td>0.401726</td>\n",
              "      <td>-0.058133</td>\n",
              "      <td>0.068653</td>\n",
              "      <td>-0.033194</td>\n",
              "      <td>0.084968</td>\n",
              "      <td>-0.208254</td>\n",
              "      <td>-0.559825</td>\n",
              "      <td>-0.026398</td>\n",
              "      <td>-0.371427</td>\n",
              "      <td>-0.232794</td>\n",
              "      <td>0.105915</td>\n",
              "      <td>0.253844</td>\n",
              "      <td>0.081080</td>\n",
              "      <td>3.67</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>4.0</td>\n",
              "      <td>1.229658</td>\n",
              "      <td>0.141004</td>\n",
              "      <td>0.045371</td>\n",
              "      <td>1.202613</td>\n",
              "      <td>0.191881</td>\n",
              "      <td>0.272708</td>\n",
              "      <td>-0.005159</td>\n",
              "      <td>0.081213</td>\n",
              "      <td>0.464960</td>\n",
              "      <td>-0.099254</td>\n",
              "      <td>-1.416907</td>\n",
              "      <td>-0.153826</td>\n",
              "      <td>-0.751063</td>\n",
              "      <td>0.167372</td>\n",
              "      <td>0.050144</td>\n",
              "      <td>-0.443587</td>\n",
              "      <td>0.002821</td>\n",
              "      <td>-0.611987</td>\n",
              "      <td>-0.045575</td>\n",
              "      <td>-0.219633</td>\n",
              "      <td>-0.167716</td>\n",
              "      <td>-0.270710</td>\n",
              "      <td>-0.154104</td>\n",
              "      <td>-0.780055</td>\n",
              "      <td>0.750137</td>\n",
              "      <td>-0.257237</td>\n",
              "      <td>0.034507</td>\n",
              "      <td>0.005168</td>\n",
              "      <td>4.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7.0</td>\n",
              "      <td>-0.644269</td>\n",
              "      <td>1.417964</td>\n",
              "      <td>1.074380</td>\n",
              "      <td>-0.492199</td>\n",
              "      <td>0.948934</td>\n",
              "      <td>0.428118</td>\n",
              "      <td>1.120631</td>\n",
              "      <td>-3.807864</td>\n",
              "      <td>0.615375</td>\n",
              "      <td>1.249376</td>\n",
              "      <td>-0.619468</td>\n",
              "      <td>0.291474</td>\n",
              "      <td>1.757964</td>\n",
              "      <td>-1.323865</td>\n",
              "      <td>0.686133</td>\n",
              "      <td>-0.076127</td>\n",
              "      <td>-1.222127</td>\n",
              "      <td>-0.358222</td>\n",
              "      <td>0.324505</td>\n",
              "      <td>-0.156742</td>\n",
              "      <td>1.943465</td>\n",
              "      <td>-1.015455</td>\n",
              "      <td>0.057504</td>\n",
              "      <td>-0.649709</td>\n",
              "      <td>-0.415267</td>\n",
              "      <td>-0.051634</td>\n",
              "      <td>-1.206921</td>\n",
              "      <td>-1.085339</td>\n",
              "      <td>40.80</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7.0</td>\n",
              "      <td>-0.894286</td>\n",
              "      <td>0.286157</td>\n",
              "      <td>-0.113192</td>\n",
              "      <td>-0.271526</td>\n",
              "      <td>2.669599</td>\n",
              "      <td>3.721818</td>\n",
              "      <td>0.370145</td>\n",
              "      <td>0.851084</td>\n",
              "      <td>-0.392048</td>\n",
              "      <td>-0.410430</td>\n",
              "      <td>-0.705117</td>\n",
              "      <td>-0.110452</td>\n",
              "      <td>-0.286254</td>\n",
              "      <td>0.074355</td>\n",
              "      <td>-0.328783</td>\n",
              "      <td>-0.210077</td>\n",
              "      <td>-0.499768</td>\n",
              "      <td>0.118765</td>\n",
              "      <td>0.570328</td>\n",
              "      <td>0.052736</td>\n",
              "      <td>-0.073425</td>\n",
              "      <td>-0.268092</td>\n",
              "      <td>-0.204233</td>\n",
              "      <td>1.011592</td>\n",
              "      <td>0.373205</td>\n",
              "      <td>-0.384157</td>\n",
              "      <td>0.011747</td>\n",
              "      <td>0.142404</td>\n",
              "      <td>93.20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9.0</td>\n",
              "      <td>-0.338262</td>\n",
              "      <td>1.119593</td>\n",
              "      <td>1.044367</td>\n",
              "      <td>-0.222187</td>\n",
              "      <td>0.499361</td>\n",
              "      <td>-0.246761</td>\n",
              "      <td>0.651583</td>\n",
              "      <td>0.069539</td>\n",
              "      <td>-0.736727</td>\n",
              "      <td>-0.366846</td>\n",
              "      <td>1.017614</td>\n",
              "      <td>0.836390</td>\n",
              "      <td>1.006844</td>\n",
              "      <td>-0.443523</td>\n",
              "      <td>0.150219</td>\n",
              "      <td>0.739453</td>\n",
              "      <td>-0.540980</td>\n",
              "      <td>0.476677</td>\n",
              "      <td>0.451773</td>\n",
              "      <td>0.203711</td>\n",
              "      <td>-0.246914</td>\n",
              "      <td>-0.633753</td>\n",
              "      <td>-0.120794</td>\n",
              "      <td>-0.385050</td>\n",
              "      <td>-0.069733</td>\n",
              "      <td>0.094199</td>\n",
              "      <td>0.246219</td>\n",
              "      <td>0.083076</td>\n",
              "      <td>3.68</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3  ...       V27       V28  Amount  Class\n",
              "0   0.0 -1.359807 -0.072781  2.536347  ...  0.133558 -0.021053  149.62      0\n",
              "1   0.0  1.191857  0.266151  0.166480  ... -0.008983  0.014724    2.69      0\n",
              "2   1.0 -1.358354 -1.340163  1.773209  ... -0.055353 -0.059752  378.66      0\n",
              "3   1.0 -0.966272 -0.185226  1.792993  ...  0.062723  0.061458  123.50      0\n",
              "4   2.0 -1.158233  0.877737  1.548718  ...  0.219422  0.215153   69.99      0\n",
              "5   2.0 -0.425966  0.960523  1.141109  ...  0.253844  0.081080    3.67      0\n",
              "6   4.0  1.229658  0.141004  0.045371  ...  0.034507  0.005168    4.99      0\n",
              "7   7.0 -0.644269  1.417964  1.074380  ... -1.206921 -1.085339   40.80      0\n",
              "8   7.0 -0.894286  0.286157 -0.113192  ...  0.011747  0.142404   93.20      0\n",
              "9   9.0 -0.338262  1.119593  1.044367  ...  0.246219  0.083076    3.68      0\n",
              "\n",
              "[10 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xTS11v4o7y4",
        "outputId": "72f4c5df-d294-4ab2-e2a4-269ada0fab08"
      },
      "source": [
        "data_unseen = df.sample(frac=0.9, random_state=42)      # Sample 10% of the data to become the unseen test set\n",
        "data = df.drop(data_unseen.index)                       # Use the remaining 90% as the training (& validation) data\n",
        "\n",
        "data.reset_index(drop=True, inplace=True)\n",
        "data_unseen.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print('Data for Model Training & Validation: ' + str(data.shape))\n",
        "print('Unseen Data For Predictions: ' + str(data_unseen.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data for Model Training & Validation: (28481, 31)\n",
            "Unseen Data For Predictions: (256326, 31)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-d4AWFtHpaKj"
      },
      "source": [
        "from pycaret.classification import *"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "E_V7urJpsVMY",
        "outputId": "06d9898e-6daf-4a7f-be28-82d539f3a321"
      },
      "source": [
        "expt_basic = setup(\n",
        "    data = data, \n",
        "    target = 'Class', \n",
        "    session_id=42,                      # Random seed to ensure reproducibility of the experiment with the same data\n",
        "    train_size=0.8,                     # 80% training data & 20% held-out validation data\n",
        "    numeric_imputation=\"median\",        # \"mean\" by default\n",
        "    log_experiment = True,       \n",
        "    categorical_imputation=\"mode\",\n",
        "    normalize=True,                  #by default normalize_method -> z-score\n",
        "    fix_imbalance = True             #by default SMOTE is applied\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Description</th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>session_id</td>\n",
              "      <td>42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Target</td>\n",
              "      <td>Class</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Target Type</td>\n",
              "      <td>Binary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Label Encoded</td>\n",
              "      <td>0: 0, 1: 1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Original Data</td>\n",
              "      <td>(28481, 31)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Missing Values</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Numeric Features</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Categorical Features</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Ordinal Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>High Cardinality Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>High Cardinality Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Transformed Train Set</td>\n",
              "      <td>(22784, 30)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Transformed Test Set</td>\n",
              "      <td>(5697, 30)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Shuffle Train-Test</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Stratify Train-Test</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Fold Generator</td>\n",
              "      <td>StratifiedKFold</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Fold Number</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>CPU Jobs</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Use GPU</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Log Experiment</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Experiment Name</td>\n",
              "      <td>clf-default-name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>USI</td>\n",
              "      <td>da2b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Imputation Type</td>\n",
              "      <td>simple</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Iterative Imputation Iteration</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Numeric Imputer</td>\n",
              "      <td>median</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Iterative Imputation Numeric Model</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>Categorical Imputer</td>\n",
              "      <td>mode</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>Iterative Imputation Categorical Model</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Unknown Categoricals Handling</td>\n",
              "      <td>least_frequent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Normalize</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>Normalize Method</td>\n",
              "      <td>zscore</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>Transformation</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>Transformation Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>PCA</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>PCA Method</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>PCA Components</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>Ignore Low Variance</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>Combine Rare Levels</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>Rare Level Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>Numeric Binning</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>Remove Outliers</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>Outliers Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>Remove Multicollinearity</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>Multicollinearity Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>Remove Perfect Collinearity</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>Clustering</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>Clustering Iteration</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>Polynomial Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>Polynomial Degree</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>Trignometry Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>Polynomial Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>Group Features</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>Feature Selection</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>Feature Selection Method</td>\n",
              "      <td>classic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>Features Selection Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>Feature Interaction</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>Feature Ratio</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>Interaction Threshold</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>Fix Imbalance</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>Fix Imbalance Method</td>\n",
              "      <td>SMOTE</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               Description             Value\n",
              "0                               session_id                42\n",
              "1                                   Target             Class\n",
              "2                              Target Type            Binary\n",
              "3                            Label Encoded        0: 0, 1: 1\n",
              "4                            Original Data       (28481, 31)\n",
              "5                           Missing Values             False\n",
              "6                         Numeric Features                30\n",
              "7                     Categorical Features                 0\n",
              "8                         Ordinal Features             False\n",
              "9                High Cardinality Features             False\n",
              "10                 High Cardinality Method              None\n",
              "11                   Transformed Train Set       (22784, 30)\n",
              "12                    Transformed Test Set        (5697, 30)\n",
              "13                      Shuffle Train-Test              True\n",
              "14                     Stratify Train-Test             False\n",
              "15                          Fold Generator   StratifiedKFold\n",
              "16                             Fold Number                10\n",
              "17                                CPU Jobs                -1\n",
              "18                                 Use GPU             False\n",
              "19                          Log Experiment              True\n",
              "20                         Experiment Name  clf-default-name\n",
              "21                                     USI              da2b\n",
              "22                         Imputation Type            simple\n",
              "23          Iterative Imputation Iteration              None\n",
              "24                         Numeric Imputer            median\n",
              "25      Iterative Imputation Numeric Model              None\n",
              "26                     Categorical Imputer              mode\n",
              "27  Iterative Imputation Categorical Model              None\n",
              "28           Unknown Categoricals Handling    least_frequent\n",
              "29                               Normalize              True\n",
              "30                        Normalize Method            zscore\n",
              "31                          Transformation             False\n",
              "32                   Transformation Method              None\n",
              "33                                     PCA             False\n",
              "34                              PCA Method              None\n",
              "35                          PCA Components              None\n",
              "36                     Ignore Low Variance             False\n",
              "37                     Combine Rare Levels             False\n",
              "38                    Rare Level Threshold              None\n",
              "39                         Numeric Binning             False\n",
              "40                         Remove Outliers             False\n",
              "41                      Outliers Threshold              None\n",
              "42                Remove Multicollinearity             False\n",
              "43             Multicollinearity Threshold              None\n",
              "44             Remove Perfect Collinearity              True\n",
              "45                              Clustering             False\n",
              "46                    Clustering Iteration              None\n",
              "47                     Polynomial Features             False\n",
              "48                       Polynomial Degree              None\n",
              "49                    Trignometry Features             False\n",
              "50                    Polynomial Threshold              None\n",
              "51                          Group Features             False\n",
              "52                       Feature Selection             False\n",
              "53                Feature Selection Method           classic\n",
              "54            Features Selection Threshold              None\n",
              "55                     Feature Interaction             False\n",
              "56                           Feature Ratio             False\n",
              "57                   Interaction Threshold              None\n",
              "58                           Fix Imbalance              True\n",
              "59                    Fix Imbalance Method             SMOTE"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "feijEnB4tygN",
        "outputId": "195264f2-245c-4bc9-b638-14b379fb6d60"
      },
      "source": [
        "models()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Reference</th>\n",
              "      <th>Turbo</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>lr</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>sklearn.linear_model._logistic.LogisticRegression</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>knn</th>\n",
              "      <td>K Neighbors Classifier</td>\n",
              "      <td>sklearn.neighbors._classification.KNeighborsCl...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>sklearn.naive_bayes.GaussianNB</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dt</th>\n",
              "      <td>Decision Tree Classifier</td>\n",
              "      <td>sklearn.tree._classes.DecisionTreeClassifier</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>svm</th>\n",
              "      <td>SVM - Linear Kernel</td>\n",
              "      <td>sklearn.linear_model._stochastic_gradient.SGDC...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rbfsvm</th>\n",
              "      <td>SVM - Radial Kernel</td>\n",
              "      <td>sklearn.svm._classes.SVC</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gpc</th>\n",
              "      <td>Gaussian Process Classifier</td>\n",
              "      <td>sklearn.gaussian_process._gpc.GaussianProcessC...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mlp</th>\n",
              "      <td>MLP Classifier</td>\n",
              "      <td>sklearn.neural_network._multilayer_perceptron....</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ridge</th>\n",
              "      <td>Ridge Classifier</td>\n",
              "      <td>sklearn.linear_model._ridge.RidgeClassifier</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rf</th>\n",
              "      <td>Random Forest Classifier</td>\n",
              "      <td>sklearn.ensemble._forest.RandomForestClassifier</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>qda</th>\n",
              "      <td>Quadratic Discriminant Analysis</td>\n",
              "      <td>sklearn.discriminant_analysis.QuadraticDiscrim...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ada</th>\n",
              "      <td>Ada Boost Classifier</td>\n",
              "      <td>sklearn.ensemble._weight_boosting.AdaBoostClas...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gbc</th>\n",
              "      <td>Gradient Boosting Classifier</td>\n",
              "      <td>sklearn.ensemble._gb.GradientBoostingClassifier</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lda</th>\n",
              "      <td>Linear Discriminant Analysis</td>\n",
              "      <td>sklearn.discriminant_analysis.LinearDiscrimina...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>et</th>\n",
              "      <td>Extra Trees Classifier</td>\n",
              "      <td>sklearn.ensemble._forest.ExtraTreesClassifier</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lightgbm</th>\n",
              "      <td>Light Gradient Boosting Machine</td>\n",
              "      <td>lightgbm.sklearn.LGBMClassifier</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                     Name  ...  Turbo\n",
              "ID                                         ...       \n",
              "lr                    Logistic Regression  ...   True\n",
              "knn                K Neighbors Classifier  ...   True\n",
              "nb                            Naive Bayes  ...   True\n",
              "dt               Decision Tree Classifier  ...   True\n",
              "svm                   SVM - Linear Kernel  ...   True\n",
              "rbfsvm                SVM - Radial Kernel  ...  False\n",
              "gpc           Gaussian Process Classifier  ...  False\n",
              "mlp                        MLP Classifier  ...  False\n",
              "ridge                    Ridge Classifier  ...   True\n",
              "rf               Random Forest Classifier  ...   True\n",
              "qda       Quadratic Discriminant Analysis  ...   True\n",
              "ada                  Ada Boost Classifier  ...   True\n",
              "gbc          Gradient Boosting Classifier  ...   True\n",
              "lda          Linear Discriminant Analysis  ...   True\n",
              "et                 Extra Trees Classifier  ...   True\n",
              "lightgbm  Light Gradient Boosting Machine  ...   True\n",
              "\n",
              "[16 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "JbD0KB5_wGAP",
        "outputId": "99107688-8c93-417e-8cb6-0c46a27582f5"
      },
      "source": [
        "top5 = compare_models(sort=\"F1\",  exclude=['rf','gbc'],fold=5, n_select=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "      <th>TT (Sec)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>et</th>\n",
              "      <td>Extra Trees Classifier</td>\n",
              "      <td>0.9993</td>\n",
              "      <td>0.9769</td>\n",
              "      <td>0.7911</td>\n",
              "      <td>0.8724</td>\n",
              "      <td>0.8227</td>\n",
              "      <td>0.8224</td>\n",
              "      <td>0.8269</td>\n",
              "      <td>1.796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lightgbm</th>\n",
              "      <td>Light Gradient Boosting Machine</td>\n",
              "      <td>0.9988</td>\n",
              "      <td>0.8984</td>\n",
              "      <td>0.7267</td>\n",
              "      <td>0.6983</td>\n",
              "      <td>0.7051</td>\n",
              "      <td>0.7045</td>\n",
              "      <td>0.7082</td>\n",
              "      <td>1.156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>knn</th>\n",
              "      <td>K Neighbors Classifier</td>\n",
              "      <td>0.9982</td>\n",
              "      <td>0.9173</td>\n",
              "      <td>0.7933</td>\n",
              "      <td>0.5547</td>\n",
              "      <td>0.6418</td>\n",
              "      <td>0.6410</td>\n",
              "      <td>0.6567</td>\n",
              "      <td>9.320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ada</th>\n",
              "      <td>Ada Boost Classifier</td>\n",
              "      <td>0.9980</td>\n",
              "      <td>0.9704</td>\n",
              "      <td>0.7711</td>\n",
              "      <td>0.5832</td>\n",
              "      <td>0.6250</td>\n",
              "      <td>0.6241</td>\n",
              "      <td>0.6494</td>\n",
              "      <td>7.014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dt</th>\n",
              "      <td>Decision Tree Classifier</td>\n",
              "      <td>0.9974</td>\n",
              "      <td>0.8191</td>\n",
              "      <td>0.6400</td>\n",
              "      <td>0.4613</td>\n",
              "      <td>0.5200</td>\n",
              "      <td>0.5188</td>\n",
              "      <td>0.5337</td>\n",
              "      <td>1.304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>svm</th>\n",
              "      <td>SVM - Linear Kernel</td>\n",
              "      <td>0.9902</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.7911</td>\n",
              "      <td>0.1988</td>\n",
              "      <td>0.2945</td>\n",
              "      <td>0.2922</td>\n",
              "      <td>0.3728</td>\n",
              "      <td>0.128</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>qda</th>\n",
              "      <td>Quadratic Discriminant Analysis</td>\n",
              "      <td>0.9863</td>\n",
              "      <td>0.9150</td>\n",
              "      <td>0.8111</td>\n",
              "      <td>0.2007</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.2847</td>\n",
              "      <td>0.3660</td>\n",
              "      <td>0.126</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lr</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.9894</td>\n",
              "      <td>0.9383</td>\n",
              "      <td>0.8778</td>\n",
              "      <td>0.1827</td>\n",
              "      <td>0.2844</td>\n",
              "      <td>0.2820</td>\n",
              "      <td>0.3800</td>\n",
              "      <td>1.052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.9796</td>\n",
              "      <td>0.9693</td>\n",
              "      <td>0.8556</td>\n",
              "      <td>0.0812</td>\n",
              "      <td>0.1481</td>\n",
              "      <td>0.1448</td>\n",
              "      <td>0.2593</td>\n",
              "      <td>0.082</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ridge</th>\n",
              "      <td>Ridge Classifier</td>\n",
              "      <td>0.9815</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.7956</td>\n",
              "      <td>0.0816</td>\n",
              "      <td>0.1473</td>\n",
              "      <td>0.1442</td>\n",
              "      <td>0.2497</td>\n",
              "      <td>0.080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lda</th>\n",
              "      <td>Linear Discriminant Analysis</td>\n",
              "      <td>0.9815</td>\n",
              "      <td>0.9584</td>\n",
              "      <td>0.7956</td>\n",
              "      <td>0.0816</td>\n",
              "      <td>0.1473</td>\n",
              "      <td>0.1442</td>\n",
              "      <td>0.2497</td>\n",
              "      <td>0.244</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
              "et                 Extra Trees Classifier    0.9993  0.9769  0.7911  0.8724   \n",
              "lightgbm  Light Gradient Boosting Machine    0.9988  0.8984  0.7267  0.6983   \n",
              "knn                K Neighbors Classifier    0.9982  0.9173  0.7933  0.5547   \n",
              "ada                  Ada Boost Classifier    0.9980  0.9704  0.7711  0.5832   \n",
              "dt               Decision Tree Classifier    0.9974  0.8191  0.6400  0.4613   \n",
              "svm                   SVM - Linear Kernel    0.9902  0.0000  0.7911  0.1988   \n",
              "qda       Quadratic Discriminant Analysis    0.9863  0.9150  0.8111  0.2007   \n",
              "lr                    Logistic Regression    0.9894  0.9383  0.8778  0.1827   \n",
              "nb                            Naive Bayes    0.9796  0.9693  0.8556  0.0812   \n",
              "ridge                    Ridge Classifier    0.9815  0.0000  0.7956  0.0816   \n",
              "lda          Linear Discriminant Analysis    0.9815  0.9584  0.7956  0.0816   \n",
              "\n",
              "              F1   Kappa     MCC  TT (Sec)  \n",
              "et        0.8227  0.8224  0.8269     1.796  \n",
              "lightgbm  0.7051  0.7045  0.7082     1.156  \n",
              "knn       0.6418  0.6410  0.6567     9.320  \n",
              "ada       0.6250  0.6241  0.6494     7.014  \n",
              "dt        0.5200  0.5188  0.5337     1.304  \n",
              "svm       0.2945  0.2922  0.3728     0.128  \n",
              "qda       0.2871  0.2847  0.3660     0.126  \n",
              "lr        0.2844  0.2820  0.3800     1.052  \n",
              "nb        0.1481  0.1448  0.2593     0.082  \n",
              "ridge     0.1473  0.1442  0.2497     0.080  \n",
              "lda       0.1473  0.1442  0.2497     0.244  "
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "id": "1ILNQtEjwUJy",
        "outputId": "e716b7eb-4651-418b-fd35-90c729711db3"
      },
      "source": [
        "et = create_model(\"et\", fold=10)\n",
        "tuned_et = tune_model(et, fold=5, optimize=\"F1\")\n",
        "print(et, \"\\n\")\n",
        "print(tuned_et)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.9996</td>\n",
              "      <td>0.9999</td>\n",
              "      <td>0.8889</td>\n",
              "      <td>0.8889</td>\n",
              "      <td>0.8889</td>\n",
              "      <td>0.8887</td>\n",
              "      <td>0.8887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.9998</td>\n",
              "      <td>0.9999</td>\n",
              "      <td>0.8889</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9412</td>\n",
              "      <td>0.9411</td>\n",
              "      <td>0.9427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.9991</td>\n",
              "      <td>0.9782</td>\n",
              "      <td>0.8000</td>\n",
              "      <td>0.8000</td>\n",
              "      <td>0.8000</td>\n",
              "      <td>0.7996</td>\n",
              "      <td>0.7996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.9991</td>\n",
              "      <td>0.9047</td>\n",
              "      <td>0.7000</td>\n",
              "      <td>0.8750</td>\n",
              "      <td>0.7778</td>\n",
              "      <td>0.7773</td>\n",
              "      <td>0.7822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.9993</td>\n",
              "      <td>0.9990</td>\n",
              "      <td>0.8889</td>\n",
              "      <td>0.8000</td>\n",
              "      <td>0.8421</td>\n",
              "      <td>0.8418</td>\n",
              "      <td>0.8429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean</th>\n",
              "      <td>0.9994</td>\n",
              "      <td>0.9763</td>\n",
              "      <td>0.8333</td>\n",
              "      <td>0.8728</td>\n",
              "      <td>0.8500</td>\n",
              "      <td>0.8497</td>\n",
              "      <td>0.8512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SD</th>\n",
              "      <td>0.0003</td>\n",
              "      <td>0.0368</td>\n",
              "      <td>0.0750</td>\n",
              "      <td>0.0735</td>\n",
              "      <td>0.0593</td>\n",
              "      <td>0.0595</td>\n",
              "      <td>0.0588</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
              "0       0.9996  0.9999  0.8889  0.8889  0.8889  0.8887  0.8887\n",
              "1       0.9998  0.9999  0.8889  1.0000  0.9412  0.9411  0.9427\n",
              "2       0.9991  0.9782  0.8000  0.8000  0.8000  0.7996  0.7996\n",
              "3       0.9991  0.9047  0.7000  0.8750  0.7778  0.7773  0.7822\n",
              "4       0.9993  0.9990  0.8889  0.8000  0.8421  0.8418  0.8429\n",
              "Mean    0.9994  0.9763  0.8333  0.8728  0.8500  0.8497  0.8512\n",
              "SD      0.0003  0.0368  0.0750  0.0735  0.0593  0.0595  0.0588"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,\n",
            "                     criterion='gini', max_depth=None, max_features='auto',\n",
            "                     max_leaf_nodes=None, max_samples=None,\n",
            "                     min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                     min_samples_leaf=1, min_samples_split=2,\n",
            "                     min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
            "                     oob_score=False, random_state=42, verbose=0,\n",
            "                     warm_start=False) \n",
            "\n",
            "ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight={},\n",
            "                     criterion='entropy', max_depth=7, max_features='sqrt',\n",
            "                     max_leaf_nodes=None, max_samples=None,\n",
            "                     min_impurity_decrease=0.05, min_impurity_split=None,\n",
            "                     min_samples_leaf=4, min_samples_split=2,\n",
            "                     min_weight_fraction_leaf=0.0, n_estimators=230, n_jobs=-1,\n",
            "                     oob_score=False, random_state=42, verbose=0,\n",
            "                     warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "X5d_Tjh0ds7c",
        "outputId": "31da5e72-9f9f-4ffc-ff25-50eb69511c89"
      },
      "source": [
        "lgbm = create_model(\"lightgbm\", fold=10)\n",
        "tuned_lgbm = tune_model(lgbm, fold=5, optimize=\"F1\")\n",
        "print(lgbm, \"\\n\")\n",
        "print(tuned_lgbm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.9989</td>\n",
              "      <td>0.9995</td>\n",
              "      <td>0.7778</td>\n",
              "      <td>0.7000</td>\n",
              "      <td>0.7368</td>\n",
              "      <td>0.7363</td>\n",
              "      <td>0.7373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.9993</td>\n",
              "      <td>0.9999</td>\n",
              "      <td>0.8889</td>\n",
              "      <td>0.8000</td>\n",
              "      <td>0.8421</td>\n",
              "      <td>0.8418</td>\n",
              "      <td>0.8429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.9987</td>\n",
              "      <td>0.8477</td>\n",
              "      <td>0.8000</td>\n",
              "      <td>0.6667</td>\n",
              "      <td>0.7273</td>\n",
              "      <td>0.7266</td>\n",
              "      <td>0.7297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.9989</td>\n",
              "      <td>0.8983</td>\n",
              "      <td>0.6000</td>\n",
              "      <td>0.8571</td>\n",
              "      <td>0.7059</td>\n",
              "      <td>0.7053</td>\n",
              "      <td>0.7166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.9991</td>\n",
              "      <td>0.9996</td>\n",
              "      <td>0.8889</td>\n",
              "      <td>0.7273</td>\n",
              "      <td>0.8000</td>\n",
              "      <td>0.7996</td>\n",
              "      <td>0.8036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean</th>\n",
              "      <td>0.9990</td>\n",
              "      <td>0.9490</td>\n",
              "      <td>0.7911</td>\n",
              "      <td>0.7502</td>\n",
              "      <td>0.7624</td>\n",
              "      <td>0.7619</td>\n",
              "      <td>0.7660</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SD</th>\n",
              "      <td>0.0002</td>\n",
              "      <td>0.0641</td>\n",
              "      <td>0.1057</td>\n",
              "      <td>0.0692</td>\n",
              "      <td>0.0507</td>\n",
              "      <td>0.0508</td>\n",
              "      <td>0.0488</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
              "0       0.9989  0.9995  0.7778  0.7000  0.7368  0.7363  0.7373\n",
              "1       0.9993  0.9999  0.8889  0.8000  0.8421  0.8418  0.8429\n",
              "2       0.9987  0.8477  0.8000  0.6667  0.7273  0.7266  0.7297\n",
              "3       0.9989  0.8983  0.6000  0.8571  0.7059  0.7053  0.7166\n",
              "4       0.9991  0.9996  0.8889  0.7273  0.8000  0.7996  0.8036\n",
              "Mean    0.9990  0.9490  0.7911  0.7502  0.7624  0.7619  0.7660\n",
              "SD      0.0002  0.0641  0.1057  0.0692  0.0507  0.0508  0.0488"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
            "               importance_type='split', learning_rate=0.1, max_depth=-1,\n",
            "               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
            "               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,\n",
            "               random_state=42, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
            "               subsample=1.0, subsample_for_bin=200000, subsample_freq=0) \n",
            "\n",
            "LGBMClassifier(bagging_fraction=0.8, bagging_freq=3, boosting_type='gbdt',\n",
            "               class_weight=None, colsample_bytree=1.0, feature_fraction=1.0,\n",
            "               importance_type='split', learning_rate=0.5, max_depth=-1,\n",
            "               min_child_samples=100, min_child_weight=0.001,\n",
            "               min_split_gain=0.3, n_estimators=190, n_jobs=-1, num_leaves=10,\n",
            "               objective=None, random_state=42, reg_alpha=0.1, reg_lambda=0.05,\n",
            "               silent=True, subsample=1.0, subsample_for_bin=200000,\n",
            "               subsample_freq=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "gFch8hb1d1V3",
        "outputId": "be505588-c0ba-4ea9-cbd1-cc3ff8f8cbb1"
      },
      "source": [
        "knn = create_model(\"knn\", fold=10)\n",
        "tuned_knn = tune_model(knn, fold=5, optimize=\"F1\")\n",
        "print(knn, \"\\n\")\n",
        "print(tuned_knn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.9991</td>\n",
              "      <td>0.9441</td>\n",
              "      <td>0.8889</td>\n",
              "      <td>0.7273</td>\n",
              "      <td>0.8000</td>\n",
              "      <td>0.7996</td>\n",
              "      <td>0.8036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.9993</td>\n",
              "      <td>0.9997</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.7500</td>\n",
              "      <td>0.8571</td>\n",
              "      <td>0.8568</td>\n",
              "      <td>0.8657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.9993</td>\n",
              "      <td>0.8999</td>\n",
              "      <td>0.8000</td>\n",
              "      <td>0.8889</td>\n",
              "      <td>0.8421</td>\n",
              "      <td>0.8418</td>\n",
              "      <td>0.8429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.9978</td>\n",
              "      <td>0.7495</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.4444</td>\n",
              "      <td>0.4434</td>\n",
              "      <td>0.4461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.9989</td>\n",
              "      <td>0.8885</td>\n",
              "      <td>0.7778</td>\n",
              "      <td>0.7000</td>\n",
              "      <td>0.7368</td>\n",
              "      <td>0.7363</td>\n",
              "      <td>0.7373</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean</th>\n",
              "      <td>0.9989</td>\n",
              "      <td>0.8963</td>\n",
              "      <td>0.7733</td>\n",
              "      <td>0.7132</td>\n",
              "      <td>0.7361</td>\n",
              "      <td>0.7356</td>\n",
              "      <td>0.7392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SD</th>\n",
              "      <td>0.0006</td>\n",
              "      <td>0.0832</td>\n",
              "      <td>0.2024</td>\n",
              "      <td>0.1249</td>\n",
              "      <td>0.1517</td>\n",
              "      <td>0.1520</td>\n",
              "      <td>0.1529</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
              "0       0.9991  0.9441  0.8889  0.7273  0.8000  0.7996  0.8036\n",
              "1       0.9993  0.9997  1.0000  0.7500  0.8571  0.8568  0.8657\n",
              "2       0.9993  0.8999  0.8000  0.8889  0.8421  0.8418  0.8429\n",
              "3       0.9978  0.7495  0.4000  0.5000  0.4444  0.4434  0.4461\n",
              "4       0.9989  0.8885  0.7778  0.7000  0.7368  0.7363  0.7373\n",
              "Mean    0.9989  0.8963  0.7733  0.7132  0.7361  0.7356  0.7392\n",
              "SD      0.0006  0.0832  0.2024  0.1249  0.1517  0.1520  0.1529"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
            "                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,\n",
            "                     weights='uniform') \n",
            "\n",
            "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='euclidean',\n",
            "                     metric_params=None, n_jobs=-1, n_neighbors=2, p=2,\n",
            "                     weights='uniform')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "-Fi7xyf8NLV4",
        "outputId": "fd342996-db95-46ab-fcfb-ccd81683a1cd"
      },
      "source": [
        "ada = create_model(\"ada\", fold=10)\n",
        "tuned_ada = tune_model(ada, fold=5, optimize=\"F1\")\n",
        "print(ada, \"\\n\")\n",
        "print(tuned_ada) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.9901</td>\n",
              "      <td>0.9778</td>\n",
              "      <td>0.7778</td>\n",
              "      <td>0.1400</td>\n",
              "      <td>0.2373</td>\n",
              "      <td>0.2347</td>\n",
              "      <td>0.3275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.9947</td>\n",
              "      <td>0.9986</td>\n",
              "      <td>0.8889</td>\n",
              "      <td>0.2581</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.3982</td>\n",
              "      <td>0.4774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.9943</td>\n",
              "      <td>0.9724</td>\n",
              "      <td>0.9000</td>\n",
              "      <td>0.2647</td>\n",
              "      <td>0.4091</td>\n",
              "      <td>0.4071</td>\n",
              "      <td>0.4864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.9982</td>\n",
              "      <td>0.9384</td>\n",
              "      <td>0.6000</td>\n",
              "      <td>0.6000</td>\n",
              "      <td>0.6000</td>\n",
              "      <td>0.5991</td>\n",
              "      <td>0.5991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.9908</td>\n",
              "      <td>0.9988</td>\n",
              "      <td>0.8889</td>\n",
              "      <td>0.1633</td>\n",
              "      <td>0.2759</td>\n",
              "      <td>0.2734</td>\n",
              "      <td>0.3788</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean</th>\n",
              "      <td>0.9936</td>\n",
              "      <td>0.9772</td>\n",
              "      <td>0.8111</td>\n",
              "      <td>0.2852</td>\n",
              "      <td>0.3844</td>\n",
              "      <td>0.3825</td>\n",
              "      <td>0.4538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SD</th>\n",
              "      <td>0.0029</td>\n",
              "      <td>0.0221</td>\n",
              "      <td>0.1146</td>\n",
              "      <td>0.1650</td>\n",
              "      <td>0.1271</td>\n",
              "      <td>0.1277</td>\n",
              "      <td>0.0942</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
              "0       0.9901  0.9778  0.7778  0.1400  0.2373  0.2347  0.3275\n",
              "1       0.9947  0.9986  0.8889  0.2581  0.4000  0.3982  0.4774\n",
              "2       0.9943  0.9724  0.9000  0.2647  0.4091  0.4071  0.4864\n",
              "3       0.9982  0.9384  0.6000  0.6000  0.6000  0.5991  0.5991\n",
              "4       0.9908  0.9988  0.8889  0.1633  0.2759  0.2734  0.3788\n",
              "Mean    0.9936  0.9772  0.8111  0.2852  0.3844  0.3825  0.4538\n",
              "SD      0.0029  0.0221  0.1146  0.1650  0.1271  0.1277  0.0942"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1.0,\n",
            "                   n_estimators=50, random_state=42) \n",
            "\n",
            "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=0.15,\n",
            "                   n_estimators=110, random_state=42)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "-VDFfrbZNET4",
        "outputId": "e43b2d55-1326-4631-ce7c-7c4e88e8bbe2"
      },
      "source": [
        "dt = create_model(\"dt\", fold=10)\n",
        "tuned_dt = tune_model(dt, fold=5, optimize=\"F1\")\n",
        "print(dt, \"\\n\")\n",
        "print(tuned_dt)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.9954</td>\n",
              "      <td>0.8740</td>\n",
              "      <td>0.7778</td>\n",
              "      <td>0.2692</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.3982</td>\n",
              "      <td>0.4560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.9963</td>\n",
              "      <td>0.9439</td>\n",
              "      <td>0.8889</td>\n",
              "      <td>0.3333</td>\n",
              "      <td>0.4848</td>\n",
              "      <td>0.4834</td>\n",
              "      <td>0.5431</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.9980</td>\n",
              "      <td>0.8992</td>\n",
              "      <td>0.8000</td>\n",
              "      <td>0.5333</td>\n",
              "      <td>0.6400</td>\n",
              "      <td>0.6390</td>\n",
              "      <td>0.6523</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.9961</td>\n",
              "      <td>0.6987</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.2500</td>\n",
              "      <td>0.3077</td>\n",
              "      <td>0.3058</td>\n",
              "      <td>0.3143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.9960</td>\n",
              "      <td>0.8295</td>\n",
              "      <td>0.6667</td>\n",
              "      <td>0.2857</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.3983</td>\n",
              "      <td>0.4349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean</th>\n",
              "      <td>0.9964</td>\n",
              "      <td>0.8491</td>\n",
              "      <td>0.7067</td>\n",
              "      <td>0.3343</td>\n",
              "      <td>0.4465</td>\n",
              "      <td>0.4450</td>\n",
              "      <td>0.4801</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SD</th>\n",
              "      <td>0.0009</td>\n",
              "      <td>0.0838</td>\n",
              "      <td>0.1689</td>\n",
              "      <td>0.1033</td>\n",
              "      <td>0.1118</td>\n",
              "      <td>0.1121</td>\n",
              "      <td>0.1129</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
              "0       0.9954  0.8740  0.7778  0.2692  0.4000  0.3982  0.4560\n",
              "1       0.9963  0.9439  0.8889  0.3333  0.4848  0.4834  0.5431\n",
              "2       0.9980  0.8992  0.8000  0.5333  0.6400  0.6390  0.6523\n",
              "3       0.9961  0.6987  0.4000  0.2500  0.3077  0.3058  0.3143\n",
              "4       0.9960  0.8295  0.6667  0.2857  0.4000  0.3983  0.4349\n",
              "Mean    0.9964  0.8491  0.7067  0.3343  0.4465  0.4450  0.4801\n",
              "SD      0.0009  0.0838  0.1689  0.1033  0.1118  0.1121  0.1129"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=42, splitter='best') \n",
            "\n",
            "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
            "                       max_depth=11, max_features=1.0, max_leaf_nodes=None,\n",
            "                       min_impurity_decrease=0.0001, min_impurity_split=None,\n",
            "                       min_samples_leaf=3, min_samples_split=10,\n",
            "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
            "                       random_state=42, splitter='best')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Udfz7sZYcKBs",
        "outputId": "bcad63ee-8173-4a15-ad4a-c2ddfb7343bf"
      },
      "source": [
        "metrics = pd.DataFrame({'Model':['Extra Trees Classifier','Light GBM','K Neighbors Classifier','Ada Boost Classifier','Decision Tree Classifier'],'Initial F1 Score':[0.8227,0.7051,0.6418,0.6250,0.5200],'Fine-Tuned F1 Score':[0.8500, 0.8000, 0.7361,0.3844,0.4465]})\n",
        "metrics"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Initial F1 Score</th>\n",
              "      <th>Fine-Tuned F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Extra Trees Classifier</td>\n",
              "      <td>0.8227</td>\n",
              "      <td>0.8500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Light GBM</td>\n",
              "      <td>0.7051</td>\n",
              "      <td>0.8000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>K Neighbors Classifier</td>\n",
              "      <td>0.6418</td>\n",
              "      <td>0.7361</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ada Boost Classifier</td>\n",
              "      <td>0.6250</td>\n",
              "      <td>0.3844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Decision Tree Classifier</td>\n",
              "      <td>0.5200</td>\n",
              "      <td>0.4465</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      Model  Initial F1 Score  Fine-Tuned F1 Score\n",
              "0    Extra Trees Classifier            0.8227               0.8500\n",
              "1                 Light GBM            0.7051               0.8000\n",
              "2    K Neighbors Classifier            0.6418               0.7361\n",
              "3      Ada Boost Classifier            0.6250               0.3844\n",
              "4  Decision Tree Classifier            0.5200               0.4465"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "zsmmpP1axpEz",
        "outputId": "46d11773-25dc-4551-f649-955894b5e865"
      },
      "source": [
        "blended_model = blend_models(estimator_list=[tuned_et, tuned_lgbm, tuned_knn, tuned_ada, tuned_dt])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.9991</td>\n",
              "      <td>0.9987</td>\n",
              "      <td>0.8000</td>\n",
              "      <td>0.8000</td>\n",
              "      <td>0.8000</td>\n",
              "      <td>0.7996</td>\n",
              "      <td>0.7996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.9991</td>\n",
              "      <td>0.9998</td>\n",
              "      <td>0.8000</td>\n",
              "      <td>0.8000</td>\n",
              "      <td>0.8000</td>\n",
              "      <td>0.7996</td>\n",
              "      <td>0.7996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.9991</td>\n",
              "      <td>0.9619</td>\n",
              "      <td>0.7500</td>\n",
              "      <td>0.7500</td>\n",
              "      <td>0.7500</td>\n",
              "      <td>0.7496</td>\n",
              "      <td>0.7496</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.9996</td>\n",
              "      <td>0.9995</td>\n",
              "      <td>0.7500</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.8571</td>\n",
              "      <td>0.8569</td>\n",
              "      <td>0.8658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.9996</td>\n",
              "      <td>0.7787</td>\n",
              "      <td>0.7500</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.8571</td>\n",
              "      <td>0.8569</td>\n",
              "      <td>0.8658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.9982</td>\n",
              "      <td>0.9926</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.6667</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>0.4992</td>\n",
              "      <td>0.5156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.9991</td>\n",
              "      <td>0.9989</td>\n",
              "      <td>0.8000</td>\n",
              "      <td>0.8000</td>\n",
              "      <td>0.8000</td>\n",
              "      <td>0.7996</td>\n",
              "      <td>0.7996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.9987</td>\n",
              "      <td>0.9992</td>\n",
              "      <td>0.8000</td>\n",
              "      <td>0.6667</td>\n",
              "      <td>0.7273</td>\n",
              "      <td>0.7266</td>\n",
              "      <td>0.7297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean</th>\n",
              "      <td>0.9993</td>\n",
              "      <td>0.9729</td>\n",
              "      <td>0.7850</td>\n",
              "      <td>0.8483</td>\n",
              "      <td>0.8092</td>\n",
              "      <td>0.8088</td>\n",
              "      <td>0.8125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SD</th>\n",
              "      <td>0.0005</td>\n",
              "      <td>0.0657</td>\n",
              "      <td>0.1566</td>\n",
              "      <td>0.1322</td>\n",
              "      <td>0.1355</td>\n",
              "      <td>0.1357</td>\n",
              "      <td>0.1325</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
              "0       1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  1.0000\n",
              "1       0.9991  0.9987  0.8000  0.8000  0.8000  0.7996  0.7996\n",
              "2       0.9991  0.9998  0.8000  0.8000  0.8000  0.7996  0.7996\n",
              "3       1.0000  1.0000  1.0000  1.0000  1.0000  1.0000  1.0000\n",
              "4       0.9991  0.9619  0.7500  0.7500  0.7500  0.7496  0.7496\n",
              "5       0.9996  0.9995  0.7500  1.0000  0.8571  0.8569  0.8658\n",
              "6       0.9996  0.7787  0.7500  1.0000  0.8571  0.8569  0.8658\n",
              "7       0.9982  0.9926  0.4000  0.6667  0.5000  0.4992  0.5156\n",
              "8       0.9991  0.9989  0.8000  0.8000  0.8000  0.7996  0.7996\n",
              "9       0.9987  0.9992  0.8000  0.6667  0.7273  0.7266  0.7297\n",
              "Mean    0.9993  0.9729  0.7850  0.8483  0.8092  0.8088  0.8125\n",
              "SD      0.0005  0.0657  0.1566  0.1322  0.1355  0.1357  0.1325"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "83__nqI5xw05",
        "outputId": "97b00367-952d-4d12-a550-d00b66f17da9"
      },
      "source": [
        "predict_model(blended_model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Voting Classifier</td>\n",
              "      <td>0.9989</td>\n",
              "      <td>0.9998</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.6667</td>\n",
              "      <td>0.6662</td>\n",
              "      <td>0.7067</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               Model  Accuracy     AUC  Recall  Prec.      F1   Kappa     MCC\n",
              "0  Voting Classifier    0.9989  0.9998     1.0    0.5  0.6667  0.6662  0.7067"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "      <th>Label</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.609851</td>\n",
              "      <td>0.745107</td>\n",
              "      <td>-0.542146</td>\n",
              "      <td>-1.577523</td>\n",
              "      <td>0.326892</td>\n",
              "      <td>0.273918</td>\n",
              "      <td>-0.208570</td>\n",
              "      <td>0.426197</td>\n",
              "      <td>-0.210632</td>\n",
              "      <td>0.841176</td>\n",
              "      <td>-0.926727</td>\n",
              "      <td>-0.959705</td>\n",
              "      <td>0.403562</td>\n",
              "      <td>0.689523</td>\n",
              "      <td>-1.648204</td>\n",
              "      <td>-0.020343</td>\n",
              "      <td>0.190532</td>\n",
              "      <td>0.977924</td>\n",
              "      <td>0.203452</td>\n",
              "      <td>0.269313</td>\n",
              "      <td>0.672886</td>\n",
              "      <td>-0.129625</td>\n",
              "      <td>-1.006585</td>\n",
              "      <td>-0.237723</td>\n",
              "      <td>-0.100095</td>\n",
              "      <td>-0.106881</td>\n",
              "      <td>-0.226333</td>\n",
              "      <td>-0.162201</td>\n",
              "      <td>0.106685</td>\n",
              "      <td>0.878272</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8533</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.150327</td>\n",
              "      <td>-0.658296</td>\n",
              "      <td>0.328628</td>\n",
              "      <td>0.581734</td>\n",
              "      <td>-0.406821</td>\n",
              "      <td>-0.071680</td>\n",
              "      <td>-0.051751</td>\n",
              "      <td>-0.040339</td>\n",
              "      <td>0.291883</td>\n",
              "      <td>0.265642</td>\n",
              "      <td>-0.642786</td>\n",
              "      <td>-1.223861</td>\n",
              "      <td>0.517514</td>\n",
              "      <td>1.065292</td>\n",
              "      <td>-0.388188</td>\n",
              "      <td>-0.113785</td>\n",
              "      <td>0.442202</td>\n",
              "      <td>-0.610847</td>\n",
              "      <td>0.198492</td>\n",
              "      <td>-0.382613</td>\n",
              "      <td>-0.401251</td>\n",
              "      <td>0.473321</td>\n",
              "      <td>1.438219</td>\n",
              "      <td>0.003440</td>\n",
              "      <td>1.365328</td>\n",
              "      <td>-0.567535</td>\n",
              "      <td>1.085829</td>\n",
              "      <td>-0.808807</td>\n",
              "      <td>0.322106</td>\n",
              "      <td>-0.212334</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.677888</td>\n",
              "      <td>0.980690</td>\n",
              "      <td>-0.104825</td>\n",
              "      <td>-0.495604</td>\n",
              "      <td>0.862654</td>\n",
              "      <td>-0.132378</td>\n",
              "      <td>-0.189592</td>\n",
              "      <td>-0.216574</td>\n",
              "      <td>0.027423</td>\n",
              "      <td>0.549495</td>\n",
              "      <td>0.373353</td>\n",
              "      <td>0.277553</td>\n",
              "      <td>0.448620</td>\n",
              "      <td>-0.908971</td>\n",
              "      <td>0.505412</td>\n",
              "      <td>-0.410704</td>\n",
              "      <td>0.453557</td>\n",
              "      <td>-1.014230</td>\n",
              "      <td>0.722500</td>\n",
              "      <td>-0.071478</td>\n",
              "      <td>-0.317122</td>\n",
              "      <td>0.104734</td>\n",
              "      <td>0.370233</td>\n",
              "      <td>0.175917</td>\n",
              "      <td>-0.638613</td>\n",
              "      <td>-0.037228</td>\n",
              "      <td>-1.348182</td>\n",
              "      <td>0.054412</td>\n",
              "      <td>-0.149826</td>\n",
              "      <td>-0.238143</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8722</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.337693</td>\n",
              "      <td>-0.274736</td>\n",
              "      <td>0.525424</td>\n",
              "      <td>0.796468</td>\n",
              "      <td>-0.184074</td>\n",
              "      <td>0.671542</td>\n",
              "      <td>1.047082</td>\n",
              "      <td>0.248738</td>\n",
              "      <td>0.546024</td>\n",
              "      <td>-0.659318</td>\n",
              "      <td>-0.491367</td>\n",
              "      <td>2.433405</td>\n",
              "      <td>1.151758</td>\n",
              "      <td>0.289968</td>\n",
              "      <td>-0.199149</td>\n",
              "      <td>1.373490</td>\n",
              "      <td>-0.797103</td>\n",
              "      <td>1.109217</td>\n",
              "      <td>-1.937122</td>\n",
              "      <td>-1.657343</td>\n",
              "      <td>0.018250</td>\n",
              "      <td>-0.124598</td>\n",
              "      <td>-0.088942</td>\n",
              "      <td>0.154208</td>\n",
              "      <td>-1.751805</td>\n",
              "      <td>-0.928749</td>\n",
              "      <td>0.381646</td>\n",
              "      <td>0.778755</td>\n",
              "      <td>0.224665</td>\n",
              "      <td>-0.311946</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.630109</td>\n",
              "      <td>1.084504</td>\n",
              "      <td>-0.418273</td>\n",
              "      <td>-0.714617</td>\n",
              "      <td>-0.203953</td>\n",
              "      <td>-0.718066</td>\n",
              "      <td>-1.176080</td>\n",
              "      <td>-0.273752</td>\n",
              "      <td>-0.311479</td>\n",
              "      <td>-0.399157</td>\n",
              "      <td>0.933864</td>\n",
              "      <td>-0.751509</td>\n",
              "      <td>-0.684925</td>\n",
              "      <td>-0.986438</td>\n",
              "      <td>0.542470</td>\n",
              "      <td>0.683063</td>\n",
              "      <td>-1.699805</td>\n",
              "      <td>-0.004630</td>\n",
              "      <td>1.323543</td>\n",
              "      <td>-1.433464</td>\n",
              "      <td>-0.809467</td>\n",
              "      <td>-0.162155</td>\n",
              "      <td>0.213790</td>\n",
              "      <td>0.300516</td>\n",
              "      <td>0.752135</td>\n",
              "      <td>-0.319065</td>\n",
              "      <td>1.596897</td>\n",
              "      <td>-0.176855</td>\n",
              "      <td>-0.180019</td>\n",
              "      <td>-0.248760</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5692</th>\n",
              "      <td>-0.792876</td>\n",
              "      <td>-0.358428</td>\n",
              "      <td>0.192456</td>\n",
              "      <td>1.904159</td>\n",
              "      <td>1.434931</td>\n",
              "      <td>-1.611633</td>\n",
              "      <td>1.422974</td>\n",
              "      <td>-1.313577</td>\n",
              "      <td>-1.617223</td>\n",
              "      <td>1.342712</td>\n",
              "      <td>-0.418960</td>\n",
              "      <td>-0.786196</td>\n",
              "      <td>0.748004</td>\n",
              "      <td>-0.706582</td>\n",
              "      <td>-0.978034</td>\n",
              "      <td>-0.728144</td>\n",
              "      <td>-1.267578</td>\n",
              "      <td>1.522632</td>\n",
              "      <td>-0.442764</td>\n",
              "      <td>0.438272</td>\n",
              "      <td>-0.731163</td>\n",
              "      <td>3.303665</td>\n",
              "      <td>-0.050214</td>\n",
              "      <td>-0.877768</td>\n",
              "      <td>1.124925</td>\n",
              "      <td>2.297921</td>\n",
              "      <td>0.430891</td>\n",
              "      <td>1.053241</td>\n",
              "      <td>0.453787</td>\n",
              "      <td>0.281149</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5693</th>\n",
              "      <td>-0.317351</td>\n",
              "      <td>-0.366245</td>\n",
              "      <td>0.357674</td>\n",
              "      <td>0.733712</td>\n",
              "      <td>-0.803995</td>\n",
              "      <td>0.760461</td>\n",
              "      <td>-0.659201</td>\n",
              "      <td>1.085452</td>\n",
              "      <td>-0.438717</td>\n",
              "      <td>-0.461691</td>\n",
              "      <td>-0.462340</td>\n",
              "      <td>-0.861872</td>\n",
              "      <td>0.118827</td>\n",
              "      <td>0.999725</td>\n",
              "      <td>-0.215859</td>\n",
              "      <td>0.288577</td>\n",
              "      <td>0.421980</td>\n",
              "      <td>-1.054187</td>\n",
              "      <td>-0.941377</td>\n",
              "      <td>0.164335</td>\n",
              "      <td>0.030463</td>\n",
              "      <td>-0.640685</td>\n",
              "      <td>-1.710610</td>\n",
              "      <td>-0.274767</td>\n",
              "      <td>-0.699647</td>\n",
              "      <td>-0.322554</td>\n",
              "      <td>1.020567</td>\n",
              "      <td>-0.667741</td>\n",
              "      <td>-0.479367</td>\n",
              "      <td>-0.168257</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5694</th>\n",
              "      <td>0.933684</td>\n",
              "      <td>-0.115702</td>\n",
              "      <td>-2.618092</td>\n",
              "      <td>-1.441488</td>\n",
              "      <td>-0.048168</td>\n",
              "      <td>-1.146105</td>\n",
              "      <td>0.328889</td>\n",
              "      <td>0.669076</td>\n",
              "      <td>-0.165322</td>\n",
              "      <td>1.089221</td>\n",
              "      <td>-0.692961</td>\n",
              "      <td>0.505514</td>\n",
              "      <td>0.883181</td>\n",
              "      <td>0.334278</td>\n",
              "      <td>0.379904</td>\n",
              "      <td>0.789155</td>\n",
              "      <td>0.888218</td>\n",
              "      <td>-1.104631</td>\n",
              "      <td>1.224481</td>\n",
              "      <td>0.229853</td>\n",
              "      <td>2.817329</td>\n",
              "      <td>1.282827</td>\n",
              "      <td>0.009532</td>\n",
              "      <td>-1.487466</td>\n",
              "      <td>0.530067</td>\n",
              "      <td>-1.358289</td>\n",
              "      <td>1.157695</td>\n",
              "      <td>-0.676103</td>\n",
              "      <td>0.445449</td>\n",
              "      <td>4.075628</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5695</th>\n",
              "      <td>1.150642</td>\n",
              "      <td>1.009918</td>\n",
              "      <td>-0.040342</td>\n",
              "      <td>-1.712375</td>\n",
              "      <td>0.084412</td>\n",
              "      <td>0.669902</td>\n",
              "      <td>-0.787517</td>\n",
              "      <td>0.791918</td>\n",
              "      <td>-0.394860</td>\n",
              "      <td>-0.397542</td>\n",
              "      <td>0.328706</td>\n",
              "      <td>0.997207</td>\n",
              "      <td>0.916904</td>\n",
              "      <td>-0.032175</td>\n",
              "      <td>1.027989</td>\n",
              "      <td>-0.962991</td>\n",
              "      <td>-0.722620</td>\n",
              "      <td>-0.335539</td>\n",
              "      <td>-0.408216</td>\n",
              "      <td>0.352163</td>\n",
              "      <td>-0.063654</td>\n",
              "      <td>0.495826</td>\n",
              "      <td>1.366231</td>\n",
              "      <td>-0.319974</td>\n",
              "      <td>1.367629</td>\n",
              "      <td>1.097675</td>\n",
              "      <td>1.990344</td>\n",
              "      <td>-0.402966</td>\n",
              "      <td>-0.266429</td>\n",
              "      <td>-0.067877</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5696</th>\n",
              "      <td>0.786483</td>\n",
              "      <td>1.084032</td>\n",
              "      <td>0.357259</td>\n",
              "      <td>-2.271573</td>\n",
              "      <td>0.444191</td>\n",
              "      <td>1.023097</td>\n",
              "      <td>-1.002152</td>\n",
              "      <td>0.620574</td>\n",
              "      <td>-0.323925</td>\n",
              "      <td>0.180552</td>\n",
              "      <td>-0.934058</td>\n",
              "      <td>-0.484084</td>\n",
              "      <td>-0.968635</td>\n",
              "      <td>-1.126791</td>\n",
              "      <td>-2.381956</td>\n",
              "      <td>0.206606</td>\n",
              "      <td>0.514647</td>\n",
              "      <td>2.499104</td>\n",
              "      <td>0.861577</td>\n",
              "      <td>-0.243627</td>\n",
              "      <td>-0.210232</td>\n",
              "      <td>-0.147176</td>\n",
              "      <td>-0.199047</td>\n",
              "      <td>-0.130979</td>\n",
              "      <td>0.113595</td>\n",
              "      <td>0.797489</td>\n",
              "      <td>1.484410</td>\n",
              "      <td>-0.211837</td>\n",
              "      <td>-0.058973</td>\n",
              "      <td>-0.319012</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8483</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5697 rows × 33 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Time        V1        V2        V3  ...    Amount  Class  Label   Score\n",
              "0     0.609851  0.745107 -0.542146 -1.577523  ...  0.878272      0      0  0.8533\n",
              "1     1.150327 -0.658296  0.328628  0.581734  ... -0.212334      0      0  0.8845\n",
              "2     0.677888  0.980690 -0.104825 -0.495604  ... -0.238143      0      0  0.8722\n",
              "3    -0.337693 -0.274736  0.525424  0.796468  ... -0.311946      0      0  0.8734\n",
              "4     0.630109  1.084504 -0.418273 -0.714617  ... -0.248760      0      0  0.8822\n",
              "...        ...       ...       ...       ...  ...       ...    ...    ...     ...\n",
              "5692 -0.792876 -0.358428  0.192456  1.904159  ...  0.281149      0      0  0.8578\n",
              "5693 -0.317351 -0.366245  0.357674  0.733712  ... -0.168257      0      0  0.8635\n",
              "5694  0.933684 -0.115702 -2.618092 -1.441488  ...  4.075628      0      0  0.8872\n",
              "5695  1.150642  1.009918 -0.040342 -1.712375  ... -0.067877      0      0  0.8948\n",
              "5696  0.786483  1.084032  0.357259 -2.271573  ... -0.319012      0      0  0.8483\n",
              "\n",
              "[5697 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "v7ljM1oGx-Yb",
        "outputId": "07a1a695-1b12-4ba1-c279-e9b9602e6b23"
      },
      "source": [
        "#- Precision-Recall Curve\n",
        "plot_model(blended_model, plot=\"pr\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "7wJE3R-05v2W",
        "outputId": "40c76459-3e00-4d42-b859-bde1cc48d495"
      },
      "source": [
        "#- Confusion Matrix\n",
        "plot_model(blended_model, plot=\"confusion_matrix\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5FDVHJ2FxxgF",
        "outputId": "e7336f58-9b1d-4312-f764-7e23903f9e0d"
      },
      "source": [
        "unseen_predictions = predict_model(blended_model, data=data_unseen)\n",
        "unseen_predictions.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "      <th>Label</th>\n",
              "      <th>Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>41505.0</td>\n",
              "      <td>-16.526507</td>\n",
              "      <td>8.584972</td>\n",
              "      <td>-18.649853</td>\n",
              "      <td>9.505594</td>\n",
              "      <td>-13.793819</td>\n",
              "      <td>-2.832404</td>\n",
              "      <td>-16.701694</td>\n",
              "      <td>7.517344</td>\n",
              "      <td>-8.507059</td>\n",
              "      <td>-14.110184</td>\n",
              "      <td>5.299236</td>\n",
              "      <td>-10.834006</td>\n",
              "      <td>1.671120</td>\n",
              "      <td>-9.373859</td>\n",
              "      <td>0.360806</td>\n",
              "      <td>-9.899247</td>\n",
              "      <td>-19.236292</td>\n",
              "      <td>-8.398552</td>\n",
              "      <td>3.101735</td>\n",
              "      <td>-1.514923</td>\n",
              "      <td>1.190739</td>\n",
              "      <td>-1.127670</td>\n",
              "      <td>-2.358579</td>\n",
              "      <td>0.673461</td>\n",
              "      <td>-1.413700</td>\n",
              "      <td>-0.462762</td>\n",
              "      <td>-2.018575</td>\n",
              "      <td>-1.042804</td>\n",
              "      <td>364.19</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0.8886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>44261.0</td>\n",
              "      <td>0.339812</td>\n",
              "      <td>-2.743745</td>\n",
              "      <td>-0.134070</td>\n",
              "      <td>-1.385729</td>\n",
              "      <td>-1.451413</td>\n",
              "      <td>1.015887</td>\n",
              "      <td>-0.524379</td>\n",
              "      <td>0.224060</td>\n",
              "      <td>0.899746</td>\n",
              "      <td>-0.565012</td>\n",
              "      <td>-0.087670</td>\n",
              "      <td>0.979427</td>\n",
              "      <td>0.076883</td>\n",
              "      <td>-0.217884</td>\n",
              "      <td>-0.136830</td>\n",
              "      <td>-2.142892</td>\n",
              "      <td>0.126956</td>\n",
              "      <td>1.752662</td>\n",
              "      <td>0.432546</td>\n",
              "      <td>0.506044</td>\n",
              "      <td>-0.213436</td>\n",
              "      <td>-0.942525</td>\n",
              "      <td>-0.526819</td>\n",
              "      <td>-1.156992</td>\n",
              "      <td>0.311211</td>\n",
              "      <td>-0.746647</td>\n",
              "      <td>0.040996</td>\n",
              "      <td>0.102038</td>\n",
              "      <td>520.12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>35484.0</td>\n",
              "      <td>1.399590</td>\n",
              "      <td>-0.590701</td>\n",
              "      <td>0.168619</td>\n",
              "      <td>-1.029950</td>\n",
              "      <td>-0.539806</td>\n",
              "      <td>0.040444</td>\n",
              "      <td>-0.712567</td>\n",
              "      <td>0.002299</td>\n",
              "      <td>-0.971747</td>\n",
              "      <td>0.756801</td>\n",
              "      <td>0.543827</td>\n",
              "      <td>0.112453</td>\n",
              "      <td>1.075384</td>\n",
              "      <td>-0.245772</td>\n",
              "      <td>0.180483</td>\n",
              "      <td>1.769860</td>\n",
              "      <td>-0.533172</td>\n",
              "      <td>-0.533300</td>\n",
              "      <td>1.192245</td>\n",
              "      <td>0.212877</td>\n",
              "      <td>0.102398</td>\n",
              "      <td>0.168269</td>\n",
              "      <td>-0.166639</td>\n",
              "      <td>-0.810250</td>\n",
              "      <td>0.505083</td>\n",
              "      <td>-0.232340</td>\n",
              "      <td>0.011409</td>\n",
              "      <td>0.004634</td>\n",
              "      <td>31.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>167123.0</td>\n",
              "      <td>-0.432071</td>\n",
              "      <td>1.647895</td>\n",
              "      <td>-1.669361</td>\n",
              "      <td>-0.349504</td>\n",
              "      <td>0.785785</td>\n",
              "      <td>-0.630647</td>\n",
              "      <td>0.276990</td>\n",
              "      <td>0.586025</td>\n",
              "      <td>-0.484715</td>\n",
              "      <td>-1.376648</td>\n",
              "      <td>-1.328335</td>\n",
              "      <td>0.223621</td>\n",
              "      <td>1.132627</td>\n",
              "      <td>-0.550875</td>\n",
              "      <td>0.616568</td>\n",
              "      <td>0.497974</td>\n",
              "      <td>0.502195</td>\n",
              "      <td>0.981343</td>\n",
              "      <td>0.101264</td>\n",
              "      <td>-0.244633</td>\n",
              "      <td>0.358932</td>\n",
              "      <td>0.873663</td>\n",
              "      <td>-0.178642</td>\n",
              "      <td>-0.017171</td>\n",
              "      <td>-0.207392</td>\n",
              "      <td>-0.157756</td>\n",
              "      <td>-0.237386</td>\n",
              "      <td>0.001934</td>\n",
              "      <td>1.50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.8709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>168473.0</td>\n",
              "      <td>2.014160</td>\n",
              "      <td>-0.137394</td>\n",
              "      <td>-1.015839</td>\n",
              "      <td>0.327269</td>\n",
              "      <td>-0.182179</td>\n",
              "      <td>-0.956571</td>\n",
              "      <td>0.043241</td>\n",
              "      <td>-0.160746</td>\n",
              "      <td>0.363241</td>\n",
              "      <td>0.259452</td>\n",
              "      <td>0.942162</td>\n",
              "      <td>0.850038</td>\n",
              "      <td>-0.616166</td>\n",
              "      <td>0.592634</td>\n",
              "      <td>-0.603845</td>\n",
              "      <td>0.091077</td>\n",
              "      <td>-0.471867</td>\n",
              "      <td>-0.333816</td>\n",
              "      <td>0.404711</td>\n",
              "      <td>-0.255293</td>\n",
              "      <td>-0.238644</td>\n",
              "      <td>-0.616400</td>\n",
              "      <td>0.347045</td>\n",
              "      <td>0.061561</td>\n",
              "      <td>-0.360196</td>\n",
              "      <td>0.174730</td>\n",
              "      <td>-0.078043</td>\n",
              "      <td>-0.070571</td>\n",
              "      <td>0.89</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.9000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Time         V1        V2         V3  ...  Amount  Class  Label   Score\n",
              "0   41505.0 -16.526507  8.584972 -18.649853  ...  364.19      1      1  0.8886\n",
              "1   44261.0   0.339812 -2.743745  -0.134070  ...  520.12      0      0  0.8887\n",
              "2   35484.0   1.399590 -0.590701   0.168619  ...   31.00      0      0  0.8629\n",
              "3  167123.0  -0.432071  1.647895  -1.669361  ...    1.50      0      0  0.8709\n",
              "4  168473.0   2.014160 -0.137394  -1.015839  ...    0.89      0      0  0.9000\n",
              "\n",
              "[5 rows x 33 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_YdyEKOx0jp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25bbecb0-2eaa-4d9f-83ff-8ae2c644acc5"
      },
      "source": [
        "#Accuracy, Precision, Recall & F1 Scores obtained.\n",
        "from pycaret.utils import check_metric\n",
        "print(\"Accuracy:\\t\", check_metric(unseen_predictions.Class, unseen_predictions.Label, 'Accuracy'))\n",
        "print(\"Precision:\\t\", check_metric(unseen_predictions.Class, unseen_predictions.Label, 'Precision'))\n",
        "print(\"Recall:\\t\", check_metric(unseen_predictions.Class, unseen_predictions.Label, 'Recall'))\n",
        "print(\"F1 Score:\\t\", check_metric(unseen_predictions.Class, unseen_predictions.Label, 'F1'))\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:\t 0.9989\n",
            "Precision:\t 0.6579\n",
            "Recall:\t 0.7973\n",
            "F1 Score:\t 0.7209\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggb0ka5ox3oi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aae486ec-03eb-4369-d38c-f8f852e4fe58"
      },
      "source": [
        "save_model(blended_model, \"drive/My Drive/blended_model\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Transformation Pipeline and Model Successfully Saved\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Pipeline(memory=None,\n",
              "          steps=[('dtypes',\n",
              "                  DataTypes_Auto_infer(categorical_features=[],\n",
              "                                       display_types=True, features_todrop=[],\n",
              "                                       id_columns=[],\n",
              "                                       ml_usecase='classification',\n",
              "                                       numerical_features=[], target='Class',\n",
              "                                       time_features=[])),\n",
              "                 ('imputer',\n",
              "                  Simple_Imputer(categorical_strategy='most frequent',\n",
              "                                 fill_value_categorical=None,\n",
              "                                 fill_value_numerical=None,\n",
              "                                 numeric_strateg...\n",
              "                                                                       class_weight=None,\n",
              "                                                                       criterion='gini',\n",
              "                                                                       max_depth=11,\n",
              "                                                                       max_features=1.0,\n",
              "                                                                       max_leaf_nodes=None,\n",
              "                                                                       min_impurity_decrease=0.0001,\n",
              "                                                                       min_impurity_split=None,\n",
              "                                                                       min_samples_leaf=3,\n",
              "                                                                       min_samples_split=10,\n",
              "                                                                       min_weight_fraction_leaf=0.0,\n",
              "                                                                       presort='deprecated',\n",
              "                                                                       random_state=42,\n",
              "                                                                       splitter='best'))],\n",
              "                                   flatten_transform=True, n_jobs=-1,\n",
              "                                   verbose=False, voting='soft',\n",
              "                                   weights=None)]],\n",
              "          verbose=False), 'drive/My Drive/blended_model.pkl')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    }
  ]
}